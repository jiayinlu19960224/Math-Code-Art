# Visualizing Music with Random Walk and Neural Networks

## Brief Description

This tutorial introduces students to a music-conditioned random-walk visualizer powered by a neural network.  
The system first learns the overall color structure of a reference image using a coordinate-based neural network, and then generates animated artwork by drawing random-walk strokes whose colors and motion are continuously controlled by features extracted from the soundtrack.

Students will learn how random walks can be used as a generative drawing mechanism, how music features influence motion dynamics and color through neural networks, and how combining stochastic paths with neural color fields can create visuals that evolve smoothly with audio.

## Tutorial Lead

Shanmei Wanyan, Coco Zhang

## Demos

**Reference image:**  
![Reference image](examples/target.png)

**Audio:**  
[liability.wav](examples/liability.wav)  
[one_last_kiss.wav](examples/one_last_kiss.wav)  
[city_of_stars.wav](examples/city_of_stars.wav)

**Full video:**  



https://github.com/user-attachments/assets/34292ed8-ef9d-4242-ba2a-2e0df55205bd
https://github.com/user-attachments/assets/99e7a90c-00fe-40c0-9328-0be9af78b8c6
https://github.com/user-attachments/assets/651304b6-9111-4fe6-bdf7-b819a7fa0d77
